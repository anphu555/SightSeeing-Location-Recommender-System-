"""
PH√ÇN T√çCH CATEGORY CONSISTENCY TRONG USER RATINGS
==================================================

Script n√†y ph√¢n t√≠ch xem user ratings c√≥ t·∫≠p trung v√†o c√πng m·ªôt th·ªÉ lo·∫°i/category kh√¥ng.
Ki·ªÉm tra xem li·ªáu user th√≠ch bi·ªÉn th√¨ c√≥ rate nhi·ªÅu ƒë·ªãa ƒëi·ªÉm bi·ªÉn kh√¥ng,
hay c√≥ rate l·∫´n l·ªôn gi·ªØa c√°c th·ªÉ lo·∫°i.

M·ª•c ƒë√≠ch:
- Ki·ªÉm tra t√≠nh nh·∫•t qu√°n (consistency) c·ªßa user preferences
- X√°c ƒë·ªãnh user c√≥ "specialized" v√†o m·ªôt s·ªë category nh·∫•t ƒë·ªãnh kh√¥ng
- T√¨m c√°c patterns trong behavior c·ªßa users
"""

import sqlite3
from collections import defaultdict, Counter
from typing import Dict, List, Tuple
import json
from pathlib import Path

class CategoryConsistencyAnalyzer:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = sqlite3.Row
        
    def get_user_ratings_with_tags(self) -> Dict[int, List[Tuple[int, float, List[str]]]]:
        """
        L·∫•y t·∫•t c·∫£ ratings c·ªßa users k√®m theo tags c·ªßa places
        
        Returns:
            Dict[user_id] -> [(place_id, score, tags), ...]
        """
        query = """
        SELECT 
            r.user_id,
            r.place_id,
            r.score,
            p.tags
        FROM rating r
        JOIN place p ON r.place_id = p.id
        WHERE r.score > 0  -- Ch·ªâ l·∫•y ratings th·ª±c s·ª± (> 0)
        ORDER BY r.user_id, r.score DESC
        """
        
        cursor = self.conn.cursor()
        cursor.execute(query)
        
        user_ratings = defaultdict(list)
        
        for row in cursor.fetchall():
            user_id = row['user_id']
            place_id = row['place_id']
            score = row['score']
            
            # Parse tags t·ª´ JSON string
            try:
                tags = json.loads(row['tags']) if row['tags'] else []
            except:
                tags = []
            
            user_ratings[user_id].append((place_id, score, tags))
        
        return user_ratings
    
    def analyze_user_category_distribution(self, user_ratings: Dict) -> Dict:
        """
        Ph√¢n t√≠ch distribution c·ªßa categories cho m·ªói user
        
        Returns:
            Dict v·ªõi th√¥ng tin ph√¢n t√≠ch cho t·ª´ng user
        """
        results = {}
        
        for user_id, ratings in user_ratings.items():
            if len(ratings) < 3:  # Skip users v·ªõi √≠t ratings
                continue
            
            # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói tag
            tag_counts = Counter()
            tag_scores = defaultdict(list)  # L∆∞u scores cho m·ªói tag
            
            total_ratings = len(ratings)
            
            for place_id, score, tags in ratings:
                for tag in tags:
                    tag_lower = tag.lower()
                    tag_counts[tag_lower] += 1
                    tag_scores[tag_lower].append(score)
            
            # T√≠nh metrics
            if not tag_counts:
                continue
                
            # Top categories
            top_categories = tag_counts.most_common(5)
            
            # Diversity score (Shannon entropy normalized)
            # Cao = ƒëa d·∫°ng, th·∫•p = t·∫≠p trung
            total_tags = sum(tag_counts.values())
            diversity = 0
            for count in tag_counts.values():
                p = count / total_tags
                diversity -= p * (p if p == 0 else p * (0 if p == 0 else (1 if p == 1 else (p * 0 if p < 1e-10 else (p * (1 / p) if p > 1 - 1e-10 else (1 - (1 - p) * (1 - p) / 2) if p > 0.5 else p * (1 - p))))))
            
            # Simpler diversity calculation
            import math
            diversity = 0
            for count in tag_counts.values():
                p = count / total_tags
                if p > 0:
                    diversity -= p * math.log2(p)
            
            # Normalize by max possible entropy
            max_entropy = math.log2(len(tag_counts)) if len(tag_counts) > 1 else 1
            normalized_diversity = diversity / max_entropy if max_entropy > 0 else 0
            
            # Concentration score: % ratings trong top category
            concentration = top_categories[0][1] / total_tags if top_categories else 0
            
            # Average score by top category
            avg_scores_by_category = {}
            for tag, _ in top_categories:
                scores = tag_scores[tag]
                avg_scores_by_category[tag] = sum(scores) / len(scores)
            
            results[user_id] = {
                'total_ratings': total_ratings,
                'total_unique_tags': len(tag_counts),
                'top_categories': top_categories,
                'diversity_score': normalized_diversity,  # 0-1, cao = ƒëa d·∫°ng
                'concentration_score': concentration,  # 0-1, cao = t·∫≠p trung
                'avg_scores_by_category': avg_scores_by_category,
                'is_specialized': concentration > 0.5,  # >50% ratings trong 1 category
            }
        
        return results
    
    def get_user_info(self, user_id: int) -> Dict:
        """L·∫•y th√¥ng tin user"""
        query = "SELECT username, preferences FROM user WHERE id = ?"
        cursor = self.conn.cursor()
        cursor.execute(query, (user_id,))
        row = cursor.fetchone()
        
        if row:
            try:
                preferences = json.loads(row['preferences']) if row['preferences'] else []
            except:
                preferences = []
            
            return {
                'username': row['username'],
                'preferences': preferences
            }
        return None
    
    def print_analysis_report(self):
        """In b√°o c√°o ph√¢n t√≠ch chi ti·∫øt"""
        print("=" * 80)
        print("PH√ÇN T√çCH CATEGORY CONSISTENCY TRONG USER RATINGS")
        print("=" * 80)
        print()
        
        user_ratings = self.get_user_ratings_with_tags()
        analysis = self.analyze_user_category_distribution(user_ratings)
        
        if not analysis:
            print("‚ö†Ô∏è  Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch")
            return
        
        print(f"üìä T·ªïng s·ªë users ƒë∆∞·ª£c ph√¢n t√≠ch: {len(analysis)}")
        print()
        
        # Statistics
        specialized_users = sum(1 for r in analysis.values() if r['is_specialized'])
        diverse_users = len(analysis) - specialized_users
        
        avg_diversity = sum(r['diversity_score'] for r in analysis.values()) / len(analysis)
        avg_concentration = sum(r['concentration_score'] for r in analysis.values()) / len(analysis)
        
        print("üìà T·ªîNG QUAN:")
        print(f"  ‚Ä¢ Users t·∫≠p trung (specialized): {specialized_users} ({specialized_users/len(analysis)*100:.1f}%)")
        print(f"    ‚Üí Users n√†y >50% ratings t·∫≠p trung v√†o 1 category")
        print(f"  ‚Ä¢ Users ƒëa d·∫°ng (diverse): {diverse_users} ({diverse_users/len(analysis)*100:.1f}%)")
        print(f"    ‚Üí Users n√†y rate nhi·ªÅu lo·∫°i ƒë·ªãa ƒëi·ªÉm kh√°c nhau")
        print()
        print(f"  ‚Ä¢ Diversity score trung b√¨nh: {avg_diversity:.3f} (0=t·∫≠p trung, 1=ƒëa d·∫°ng)")
        print(f"  ‚Ä¢ Concentration score trung b√¨nh: {avg_concentration:.3f} (t·ªâ l·ªá ratings trong top category)")
        print()
        
        # Sort users by concentration (most specialized first)
        sorted_users = sorted(analysis.items(), key=lambda x: x[1]['concentration_score'], reverse=True)
        
        print("=" * 80)
        print("TOP 10 USERS T·∫¨P TRUNG NH·∫§T (SPECIALIZED):")
        print("=" * 80)
        
        for i, (user_id, data) in enumerate(sorted_users[:10], 1):
            user_info = self.get_user_info(user_id)
            username = user_info['username'] if user_info else f"User {user_id}"
            preferences = user_info['preferences'] if user_info else []
            
            print(f"\n{i}. {username} (ID: {user_id})")
            print(f"   Preferences: {preferences}")
            print(f"   Total ratings: {data['total_ratings']}")
            print(f"   Concentration: {data['concentration_score']:.1%} | Diversity: {data['diversity_score']:.3f}")
            print(f"   Top categories:")
            
            for j, (tag, count) in enumerate(data['top_categories'][:3], 1):
                pct = count / data['total_ratings'] * 100
                avg_score = data['avg_scores_by_category'].get(tag, 0)
                print(f"      {j}. {tag}: {count} ratings ({pct:.1f}%) - avg score: {avg_score:.2f}")
        
        print()
        print("=" * 80)
        print("TOP 10 USERS ƒêA D·∫†NG NH·∫§T (DIVERSE):")
        print("=" * 80)
        
        # Sort by diversity score
        sorted_diverse = sorted(analysis.items(), key=lambda x: x[1]['diversity_score'], reverse=True)
        
        for i, (user_id, data) in enumerate(sorted_diverse[:10], 1):
            user_info = self.get_user_info(user_id)
            username = user_info['username'] if user_info else f"User {user_id}"
            preferences = user_info['preferences'] if user_info else []
            
            print(f"\n{i}. {username} (ID: {user_id})")
            print(f"   Preferences: {preferences}")
            print(f"   Total ratings: {data['total_ratings']}")
            print(f"   Diversity: {data['diversity_score']:.3f} | Concentration: {data['concentration_score']:.1%}")
            print(f"   Top categories:")
            
            for j, (tag, count) in enumerate(data['top_categories'][:3], 1):
                pct = count / data['total_ratings'] * 100
                avg_score = data['avg_scores_by_category'].get(tag, 0)
                print(f"      {j}. {tag}: {count} ratings ({pct:.1f}%) - avg score: {avg_score:.2f}")
        
        print()
        print("=" * 80)
        print("PH√ÇN T√çCH PREFERENCE MATCHING:")
        print("=" * 80)
        print("Ki·ªÉm tra xem user c√≥ rate ƒë√∫ng lo·∫°i ƒë·ªãa ƒëi·ªÉm trong preferences kh√¥ng")
        print()
        
        matched = 0
        not_matched = 0
        
        for user_id, data in analysis.items():
            user_info = self.get_user_info(user_id)
            if not user_info or not user_info['preferences']:
                continue
            
            preferences_lower = [p.lower() for p in user_info['preferences']]
            top_category = data['top_categories'][0][0] if data['top_categories'] else None
            
            if top_category and any(pref in top_category or top_category in pref for pref in preferences_lower):
                matched += 1
            else:
                not_matched += 1
                
                # Print mismatched cases
                if not_matched <= 10:  # Ch·ªâ in 10 cases ƒë·∫ßu
                    print(f"‚ùå {user_info['username']} (ID: {user_id})")
                    print(f"   Preferences: {user_info['preferences']}")
                    print(f"   Top rated category: {top_category} ({data['top_categories'][0][1]} ratings)")
                    print()
        
        total_with_pref = matched + not_matched
        if total_with_pref > 0:
            print(f"üìä T·ªïng k·∫øt:")
            print(f"  ‚Ä¢ Users rate ƒë√∫ng preferences: {matched} ({matched/total_with_pref*100:.1f}%)")
            print(f"  ‚Ä¢ Users rate kh√°c preferences: {not_matched} ({not_matched/total_with_pref*100:.1f}%)")
        
        print()
        print("=" * 80)
        print("üí° K·∫æT LU·∫¨N V√Ä KHUY·∫æN NGH·ªä:")
        print("=" * 80)
        
        if avg_concentration > 0.5:
            print("‚úì D·ªØ li·ªáu T·ªêT: Users c√≥ xu h∆∞·ªõng rate t·∫≠p trung v√†o m·ªôt s·ªë categories nh·∫•t ƒë·ªãnh")
            print("  ‚Üí H·ªá th·ªëng recommendation c√≥ th·ªÉ ho·∫°t ƒë·ªông hi·ªáu qu·∫£")
            print("  ‚Üí User th√≠ch bi·ªÉn th√¨ s·∫Ω ƒë∆∞·ª£c recommend bi·ªÉn (nh∆∞ b·∫°n test)")
        else:
            print("‚ö†Ô∏è  D·ªØ li·ªáu C·∫¶N C·∫¢I THI·ªÜN: Users rate kh√° ƒëa d·∫°ng, kh√¥ng t·∫≠p trung")
            print("  ‚Üí C√≥ th·ªÉ kh√≥ ƒë·ªÉ x√°c ƒë·ªãnh preferences r√µ r√†ng")
            print("  ‚Üí C·∫ßn th√™m d·ªØ li·ªáu ho·∫∑c c·∫£i thi·ªán c√°ch collect interactions")
        
        print()
        
        if not_matched > matched:
            print("‚ö†Ô∏è  L∆ØU √ù: Nhi·ªÅu users rate kh√°c v·ªõi preferences ƒë√£ set")
            print("  ‚Üí C√≥ th·ªÉ preferences kh√¥ng ph·∫£n √°nh ƒë√∫ng s·ªü th√≠ch")
            print("  ‚Üí Ho·∫∑c users kh√°m ph√° nhi·ªÅu lo·∫°i ƒë·ªãa ƒëi·ªÉm kh√°c nhau")
        else:
            print("‚úì T·ªêT: Ph·∫ßn l·ªõn users rate ƒë√∫ng v·ªõi preferences ƒë√£ set")
            print("  ‚Üí Preferences ph·∫£n √°nh t·ªët s·ªü th√≠ch th·ª±c t·∫ø")
        
        print()
    
    def close(self):
        self.conn.close()


def main():
    # Database ·ªü parent directory (backend/)
    db_path = Path(__file__).parent.parent / "vietnamtravel.db"
    
    if not db_path.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y database: {db_path}")
        return
    
    print(f"üìÇ ƒêang ph√¢n t√≠ch database: {db_path}")
    print()
    
    analyzer = CategoryConsistencyAnalyzer(str(db_path))
    
    try:
        analyzer.print_analysis_report()
    finally:
        analyzer.close()


if __name__ == "__main__":
    main()
