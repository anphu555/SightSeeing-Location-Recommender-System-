import pandas as pd
import json
import numpy as np

# Load evaluation results
df = pd.read_csv('evaluation_detailed.csv')

print("=" * 80)
print("PHÃ‚N TÃCH Káº¾T QUáº¢ EVALUATION - THUáº¬T TOÃN RECOMMENDATION")
print("=" * 80)
print()

# Basic stats
print(f"ğŸ“Š Tá»•ng sá»‘ users Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡: {len(df)}")
print(f"ğŸ“Š Trung bÃ¬nh relevant items/user: {df['num_relevant'].mean():.2f}")
print(f"ğŸ“Š Min relevant items: {df['num_relevant'].min()}")
print(f"ğŸ“Š Max relevant items: {df['num_relevant'].max()}")
print()

print("=" * 80)
print("Káº¾T QUáº¢ METRICS CHÃNH")
print("=" * 80)
print()

# Precision
print("ğŸ¯ PRECISION (Äá»™ chÃ­nh xÃ¡c recommendations):")
print(f"   â€¢ Precision@5:  {df['precision@5'].mean():.4f} ({df['precision@5'].mean()*100:.2f}%)")
print(f"   â€¢ Precision@10: {df['precision@10'].mean():.4f} ({df['precision@10'].mean()*100:.2f}%)")
print(f"   â€¢ Precision@20: {df['precision@20'].mean():.4f} ({df['precision@20'].mean()*100:.2f}%)")
print()

# Recall  
print("ğŸ“ˆ RECALL (Tá»‰ lá»‡ tÃ¬m Ä‘Æ°á»£c relevant items):")
print(f"   â€¢ Recall@5:  {df['recall@5'].mean():.4f} ({df['recall@5'].mean()*100:.2f}%)")
print(f"   â€¢ Recall@10: {df['recall@10'].mean():.4f} ({df['recall@10'].mean()*100:.2f}%)")
print(f"   â€¢ Recall@20: {df['recall@20'].mean():.4f} ({df['recall@20'].mean()*100:.2f}%)")
print()

# F1
print("âš–ï¸  F1 SCORE (CÃ¢n báº±ng Precision & Recall):")
print(f"   â€¢ F1@5:  {df['f1@5'].mean():.4f} ({df['f1@5'].mean()*100:.2f}%)")
print(f"   â€¢ F1@10: {df['f1@10'].mean():.4f} ({df['f1@10'].mean()*100:.2f}%)")
print(f"   â€¢ F1@20: {df['f1@20'].mean():.4f} ({df['f1@20'].mean()*100:.2f}%)")
print()

# NDCG
print("ğŸ† NDCG (Ranking Quality):")
print(f"   â€¢ NDCG@5:  {df['ndcg@5'].mean():.4f} ({df['ndcg@5'].mean()*100:.2f}%)")
print(f"   â€¢ NDCG@10: {df['ndcg@10'].mean():.4f} ({df['ndcg@10'].mean()*100:.2f}%)")
print(f"   â€¢ NDCG@20: {df['ndcg@20'].mean():.4f} ({df['ndcg@20'].mean()*100:.2f}%)")
print()

# MAP
print("ğŸ“Š MAP (Mean Average Precision):")
print(f"   â€¢ MAP: {df['map'].mean():.4f} ({df['map'].mean()*100:.2f}%)")
print()

print("=" * 80)
print("PHÃ‚N TÃCH CHI TIáº¾T")
print("=" * 80)
print()

# Distribution analysis
print("ğŸ“Š PHÃ‚N PHá»I Káº¾T QUáº¢:")
print(f"   â€¢ Users cÃ³ Precision@5 = 0: {(df['precision@5'] == 0).sum()} ({(df['precision@5'] == 0).sum()/len(df)*100:.1f}%)")
print(f"   â€¢ Users cÃ³ Precision@5 > 0.2: {(df['precision@5'] > 0.2).sum()} ({(df['precision@5'] > 0.2).sum()/len(df)*100:.1f}%)")
print(f"   â€¢ Users cÃ³ Precision@5 > 0.4: {(df['precision@5'] > 0.4).sum()} ({(df['precision@5'] > 0.4).sum()/len(df)*100:.1f}%)")
print()

# Top/Bottom performers
print("ğŸ† TOP 10 USERS (best Precision@5):")
top10 = df.nlargest(10, 'precision@5')[['user_id', 'precision@5', 'recall@5', 'ndcg@5', 'num_relevant']]
for idx, row in top10.iterrows():
    print(f"   User {row['user_id']:3d}: P@5={row['precision@5']:.3f}, R@5={row['recall@5']:.3f}, NDCG@5={row['ndcg@5']:.3f} ({row['num_relevant']} relevant)")
print()

print("âŒ WORST 10 USERS (worst Precision@5):")
worst10 = df.nsmallest(10, 'precision@5')[['user_id', 'precision@5', 'recall@5', 'ndcg@5', 'num_relevant']]
for idx, row in worst10.iterrows():
    print(f"   User {row['user_id']:3d}: P@5={row['precision@5']:.3f}, R@5={row['recall@5']:.3f}, NDCG@5={row['ndcg@5']:.3f} ({row['num_relevant']} relevant)")
print()

# Load JSON results for coverage/diversity
with open('evaluation_results.json', 'r') as f:
    results = json.load(f)

print("=" * 80)
print("COVERAGE & DIVERSITY")
print("=" * 80)
print()
print(f"ğŸ“Š Coverage (Catalog coverage): {results['coverage']:.4f} ({results['coverage']*100:.2f}%)")
print(f"   â†’ Tá»‰ lá»‡ items Ä‘Æ°á»£c recommend Ã­t nháº¥t 1 láº§n")
print()
print(f"ğŸ¨ Diversity: {results['diversity']:.4f} ({results['diversity']*100:.2f}%)")
print(f"   â†’ Äá»™ Ä‘a dáº¡ng trong recommendations")
print()

print("=" * 80)
print("ÄÃNH GIÃ Tá»”NG QUAN")
print("=" * 80)
print()

avg_p5 = df['precision@5'].mean()
avg_r5 = df['recall@5'].mean()
avg_ndcg5 = df['ndcg@5'].mean()
avg_map = df['map'].mean()

if avg_p5 > 0.3 and avg_r5 > 0.3:
    print("âœ… Káº¾T QUáº¢ Tá»T: Thuáº­t toÃ¡n hoáº¡t Ä‘á»™ng hiá»‡u quáº£")
    grade = "A"
elif avg_p5 > 0.2 and avg_r5 > 0.2:
    print("âœ“ Káº¾T QUáº¢ KHÃ: Thuáº­t toÃ¡n hoáº¡t Ä‘á»™ng tÆ°Æ¡ng Ä‘á»‘i tá»‘t")
    grade = "B"
elif avg_p5 > 0.1 and avg_r5 > 0.1:
    print("âš ï¸  Káº¾T QUáº¢ TRUNG BÃŒNH: Cáº§n cáº£i thiá»‡n thuáº­t toÃ¡n")
    grade = "C"
else:
    print("âŒ Káº¾T QUáº¢ Yáº¾U: Cáº§n cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ")
    grade = "D"

print()
print(f"ğŸ“ Xáº¿p loáº¡i: {grade}")
print()

print("=" * 80)
print("PHÃ‚N TÃCH NGUYÃŠN NHÃ‚N")
print("=" * 80)
print()

if avg_p5 < 0.3:
    print("ğŸ” Táº I SAO Káº¾T QUáº¢ CHÆ¯A Tá»T?")
    print()
    
    zero_precision = (df['precision@5'] == 0).sum()
    if zero_precision > len(df) * 0.3:
        print(f"1. âŒ {zero_precision}/{len(df)} users ({zero_precision/len(df)*100:.1f}%) cÃ³ Precision@5 = 0")
        print("   â†’ Model khÃ´ng recommend Ä‘Ãºng items user thÃ­ch")
        print("   â†’ CÃ³ thá»ƒ do:")
        print("      â€¢ Data quÃ¡ sparse (Ã­t interactions)")
        print("      â€¢ Features khÃ´ng tá»‘t (tags khÃ´ng phÃ¢n biá»‡t rÃµ)")
        print("      â€¢ Model chÆ°a há»c Ä‘Æ°á»£c patterns")
        print()
    
    low_relevant = df['num_relevant'].mean()
    if low_relevant < 5:
        print(f"2. âš ï¸  Trung bÃ¬nh chá»‰ {low_relevant:.1f} relevant items/user")
        print("   â†’ Test set quÃ¡ nhá», khÃ³ Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c")
        print("   â†’ Cáº§n thÃªm dá»¯ liá»‡u interactions")
        print()
    
    if results['coverage'] < 0.3:
        print(f"3. âš ï¸  Coverage tháº¥p ({results['coverage']*100:.1f}%)")
        print("   â†’ Model chá»‰ recommend má»™t sá»‘ items phá»• biáº¿n")
        print("   â†’ Thiáº¿u diversity, khÃ´ng explore Ä‘á»§")
        print()

print("=" * 80)
print("Gá»¢I Ã Cáº¢I THIá»†N")
print("=" * 80)
print()

print("ğŸ’¡ HÆ¯á»šNG GIáº¢I QUYáº¾T:")
print()
print("1. ğŸ“Š Cáº£i thiá»‡n dá»¯ liá»‡u:")
print("   â€¢ Táº¡o users vá»›i preferences rÃµ rÃ ng hÆ¡n")
print("   â€¢ TÄƒng sá»‘ lÆ°á»£ng interactions (ratings/likes)")
print("   â€¢ Äáº£m báº£o users rate Ä‘Ãºng thá»ƒ loáº¡i (beach â†’ beach)")
print("   â†’ Cháº¡y: python create_improved_test_data.py")
print()

print("2. ğŸ”§ Cáº£i thiá»‡n features:")
print("   â€¢ LÃ m sáº¡ch tags (loáº¡i bá» tags quÃ¡ chung nhÆ° 'sightseeing')")
print("   â€¢ ThÃªm features: location, price, season")
print("   â€¢ Sá»­ dá»¥ng embeddings tá»« descriptions")
print()

print("3. ğŸ¤– Cáº£i thiá»‡n model:")
print("   â€¢ Thá»­ collaborative filtering")
print("   â€¢ Hybrid approach (content + collaborative)")
print("   â€¢ Fine-tune hyperparameters")
print()

print("4. âœ… Test láº¡i:")
print("   â€¢ Sau khi cáº£i thiá»‡n, cháº¡y láº¡i evaluation")
print("   â€¢ So sÃ¡nh káº¿t quáº£ vá»›i baseline hiá»‡n táº¡i")
print()

print("=" * 80)
print("Káº¾T LUáº¬N")
print("=" * 80)
print()
print(f"Thuáº­t toÃ¡n hiá»‡n táº¡i Ä‘áº¡t Precision@5 = {avg_p5:.2%}, Recall@5 = {avg_r5:.2%}")
print(f"ÄÃ¢y lÃ  káº¿t quáº£ {grade} - ", end="")
if grade in ['A', 'B']:
    print("cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘Æ°á»£c nhÆ°ng nÃªn cáº£i thiá»‡n thÃªm")
else:
    print("cáº§n cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trÆ°á»›c khi deploy production")
print()
print("ğŸ“ Report saved to: evaluation_analysis_report.txt")
