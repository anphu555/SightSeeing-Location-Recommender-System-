"""
PHÃ‚N TÃCH PHÆ¯Æ NG PHÃP EVALUATION
=================================

Script nÃ y giáº£i thÃ­ch vÃ  phÃ¢n tÃ­ch cÃ¡ch evaluation Ä‘Æ°á»£c thá»±c hiá»‡n,
Ä‘áº·c biá»‡t lÃ  cÃ¡ch xÃ¡c Ä‘á»‹nh "relevant items" (ground truth) Ä‘á»ƒ tÃ­nh precision/recall.

Váº¤N Äá»€: LÃ m sao biáº¿t Ä‘Æ°á»£c item nÃ o lÃ  "relevant" cho user khi chá»‰ cÃ³ ratings?
GIáº¢I ÄÃP: Train/Test Split methodology
"""

import sqlite3
from collections import defaultdict
import json
from pathlib import Path
import numpy as np

class EvaluationMethodologyAnalyzer:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.conn.row_factory = sqlite3.Row
        
    def get_user_interactions(self):
        """Láº¥y táº¥t cáº£ interactions cá»§a users"""
        query = """
        SELECT 
            r.user_id,
            r.place_id,
            r.score,
            p.name as place_name,
            p.tags
        FROM rating r
        JOIN place p ON r.place_id = p.id
        WHERE r.score > 0
        ORDER BY r.user_id, r.score DESC
        """
        
        cursor = self.conn.cursor()
        cursor.execute(query)
        
        user_interactions = defaultdict(list)
        
        for row in cursor.fetchall():
            try:
                tags = json.loads(row['tags']) if row['tags'] else []
            except:
                tags = []
            
            user_interactions[row['user_id']].append({
                'place_id': row['place_id'],
                'place_name': row['place_name'],
                'score': row['score'],
                'tags': tags
            })
        
        return user_interactions
    
    def simulate_train_test_split(self, user_interactions, test_ratio=0.2):
        """
        MÃ´ phá»ng train/test split nhÆ° trong evaluation
        
        QUAN TRá»ŒNG: ÄÃ¢y lÃ  cÃ¡ch xÃ¡c Ä‘á»‹nh "ground truth"!
        - Train set: Model há»c tá»« Ä‘Ã¢y
        - Test set: Items nÃ y Ä‘Æ°á»£c giáº¥u Ä‘i, dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
        - Ground truth = Test set (nhá»¯ng items user thá»±c sá»± thÃ­ch nhÆ°ng model chÆ°a biáº¿t)
        """
        train_data = defaultdict(list)
        test_data = defaultdict(list)
        
        for user_id, interactions in user_interactions.items():
            # Chá»‰ láº¥y positive interactions (score >= 3.0)
            positive_interactions = [i for i in interactions if i['score'] >= 3.0]
            
            if len(positive_interactions) < 5:
                continue
            
            # Shuffle
            interactions_copy = positive_interactions.copy()
            np.random.shuffle(interactions_copy)
            
            # Split
            n_test = max(1, int(len(interactions_copy) * test_ratio))
            
            test_data[user_id] = interactions_copy[:n_test]
            train_data[user_id] = interactions_copy[n_test:]
        
        return train_data, test_data
    
    def analyze_evaluation_process(self):
        """PhÃ¢n tÃ­ch chi tiáº¿t quy trÃ¬nh evaluation"""
        print("=" * 80)
        print("PHÃ‚N TÃCH PHÆ¯Æ NG PHÃP EVALUATION")
        print("=" * 80)
        print()
        
        print("ğŸ“š GIáº¢I THÃCH PHÆ¯Æ NG PHÃP:")
        print("-" * 80)
        print()
        print("â“ CÃ‚U Há»I: LÃ m sao biáº¿t Ä‘Æ°á»£c item nÃ o lÃ  'relevant' Ä‘á»ƒ tÃ­nh precision/recall?")
        print()
        print("ğŸ’¡ GIáº¢I ÄÃP: Sá»­ dá»¥ng Train/Test Split Methodology")
        print()
        print("ğŸ” QUY TRÃŒNH:")
        print()
        print("1. THU THáº¬P Dá»® LIá»†U:")
        print("   â€¢ Láº¥y táº¥t cáº£ interactions cá»§a user (ratings, likes)")
        print("   â€¢ Chá»‰ giá»¯ POSITIVE interactions (score >= 3.0 hoáº·c like=True)")
        print("   â†’ Giáº£ Ä‘á»‹nh: Score cao = user thÃ­ch item Ä‘Ã³")
        print()
        
        print("2. CHIA Dá»® LIá»†U (Train/Test Split):")
        print("   â€¢ Train set (80%): Model há»c tá»« Ä‘Ã¢y")
        print("   â€¢ Test set (20%): GIáº¤U ÄI, dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡")
        print()
        print("   VÃ­ dá»¥ User A thÃ­ch 10 Ä‘á»‹a Ä‘iá»ƒm (score >= 3.0):")
        print("   â”œâ”€ Train: 8 Ä‘á»‹a Ä‘iá»ƒm (model biáº¿t)")
        print("   â””â”€ Test: 2 Ä‘á»‹a Ä‘iá»ƒm (GIáº¤U ÄI - ground truth)")
        print()
        
        print("3. MODEL Há»ŒC VÃ€ Dá»° ÄOÃN:")
        print("   â€¢ Model há»c tá»« Train set (8 Ä‘á»‹a Ä‘iá»ƒm)")
        print("   â€¢ Model dá»± Ä‘oÃ¡n top-K recommendations cho User A")
        print("   â€¢ VÃ­ dá»¥: Recommend top-5 = [P1, P2, P3, P4, P5]")
        print()
        
        print("4. ÄÃNH GIÃ (So sÃ¡nh vá»›i Ground Truth):")
        print("   â€¢ Ground truth = Test set (2 Ä‘á»‹a Ä‘iá»ƒm Ä‘Ã£ giáº¥u)")
        print("   â€¢ Kiá»ƒm tra: Trong top-5 cÃ³ bao nhiÃªu Ä‘á»‹a Ä‘iá»ƒm thuá»™c test set?")
        print()
        print("   Náº¿u top-5 cÃ³ 1 Ä‘á»‹a Ä‘iá»ƒm trong test set:")
        print("   â”œâ”€ Precision@5 = 1/5 = 0.2 (20% recommendations Ä‘Ãºng)")
        print("   â”œâ”€ Recall@5 = 1/2 = 0.5 (tÃ¬m Ä‘Æ°á»£c 50% relevant items)")
        print("   â””â”€ F1@5 = 2 * (0.2 * 0.5) / (0.2 + 0.5) = 0.286")
        print()
        
        print("=" * 80)
        print("ğŸ“Š PHÃ‚N TÃCH Dá»® LIá»†U THá»°C Táº¾:")
        print("=" * 80)
        print()
        
        # Load vÃ  phÃ¢n tÃ­ch data
        user_interactions = self.get_user_interactions()
        
        print(f"ğŸ“ˆ Tá»•ng sá»‘ users cÃ³ interactions: {len(user_interactions)}")
        print()
        
        # Simulate split
        train_data, test_data = self.simulate_train_test_split(user_interactions)
        
        print(f"ğŸ‘¥ Users Ä‘á»§ Ä‘iá»u kiá»‡n cho evaluation: {len(test_data)}")
        print(f"   (Cáº§n Ã­t nháº¥t 5 positive interactions)")
        print()
        
        if not test_data:
            print("âš ï¸  KHÃ”NG CÃ“ Dá»® LIá»†U Äá»‚ PHÃ‚N TÃCH!")
            print("   Cáº§n táº¡o test data vá»›i create_test_data.py trÆ°á»›c")
            return
        
        print("=" * 80)
        print("VÃ Dá»¤ Cá»¤ THá»‚: Top 5 Users")
        print("=" * 80)
        print()
        
        for i, (user_id, test_items) in enumerate(list(test_data.items())[:5], 1):
            train_items = train_data[user_id]
            
            print(f"{i}. USER {user_id}:")
            print(f"   â€¢ Train set: {len(train_items)} items (model biáº¿t)")
            print(f"   â€¢ Test set: {len(test_items)} items (ground truth - GIáº¤U ÄI)")
            print()
            
            print(f"   ğŸ“š Train items (model há»c tá»« Ä‘Ã¢y):")
            for j, item in enumerate(train_items[:3], 1):
                tags_str = ", ".join(item['tags'][:3])
                print(f"      {j}. {item['place_name'][:40]} (score: {item['score']:.1f}) [{tags_str}]")
            if len(train_items) > 3:
                print(f"      ... vÃ  {len(train_items) - 3} items khÃ¡c")
            print()
            
            print(f"   ğŸ¯ Test items (ground truth - Ä‘á»ƒ Ä‘Ã¡nh giÃ¡):")
            for j, item in enumerate(test_items, 1):
                tags_str = ", ".join(item['tags'][:3])
                print(f"      {j}. {item['place_name'][:40]} (score: {item['score']:.1f}) [{tags_str}]")
            print()
            
            # PhÃ¢n tÃ­ch tags
            train_tags = defaultdict(int)
            test_tags = defaultdict(int)
            
            for item in train_items:
                for tag in item['tags']:
                    train_tags[tag.lower()] += 1
            
            for item in test_items:
                for tag in item['tags']:
                    test_tags[tag.lower()] += 1
            
            top_train_tags = sorted(train_tags.items(), key=lambda x: x[1], reverse=True)[:3]
            top_test_tags = sorted(test_tags.items(), key=lambda x: x[1], reverse=True)[:3]
            
            print(f"   ğŸ“Š Top tags trong train: {[f'{t}({c})' for t, c in top_train_tags]}")
            print(f"   ğŸ“Š Top tags trong test: {[f'{t}({c})' for t, c in top_test_tags]}")
            
            # Check consistency
            train_tag_set = set(train_tags.keys())
            test_tag_set = set(test_tags.keys())
            overlap = len(train_tag_set & test_tag_set) / len(test_tag_set) if test_tag_set else 0
            
            print(f"   âœ“ Tag overlap: {overlap:.1%} (test tags cÅ©ng xuáº¥t hiá»‡n trong train)")
            print()
            print("-" * 80)
            print()
        
        print("=" * 80)
        print("ğŸ’¡ ÄÃNH GIÃ TÃNH Há»¢P LÃ Cá»¦A PHÆ¯Æ NG PHÃP:")
        print("=" * 80)
        print()
        
        # Calculate overall statistics
        total_train_items = sum(len(items) for items in train_data.values())
        total_test_items = sum(len(items) for items in test_data.values())
        avg_train = total_train_items / len(train_data) if train_data else 0
        avg_test = total_test_items / len(test_data) if test_data else 0
        
        print(f"ğŸ“Š THá»NG KÃŠ Tá»”NG QUAN:")
        print(f"   â€¢ Trung bÃ¬nh train items/user: {avg_train:.1f}")
        print(f"   â€¢ Trung bÃ¬nh test items/user: {avg_test:.1f}")
        print(f"   â€¢ Tá»‰ lá»‡ train/test: {avg_train/(avg_train+avg_test):.1%} / {avg_test/(avg_train+avg_test):.1%}")
        print()
        
        # Analyze tag consistency
        tag_overlaps = []
        for user_id, test_items in test_data.items():
            train_items = train_data[user_id]
            
            train_tags = set()
            test_tags = set()
            
            for item in train_items:
                train_tags.update([t.lower() for t in item['tags']])
            
            for item in test_items:
                test_tags.update([t.lower() for t in item['tags']])
            
            if test_tags:
                overlap = len(train_tags & test_tags) / len(test_tags)
                tag_overlaps.append(overlap)
        
        avg_overlap = np.mean(tag_overlaps) if tag_overlaps else 0
        
        print(f"ğŸ“ˆ TAG CONSISTENCY:")
        print(f"   â€¢ Average tag overlap: {avg_overlap:.1%}")
        print()
        
        if avg_overlap > 0.6:
            print("   âœ“ Tá»T: Test items cÃ³ tags tÆ°Æ¡ng tá»± train items")
            print("     â†’ Model cÃ³ thá»ƒ há»c patterns tá»« train vÃ  Ã¡p dá»¥ng cho test")
            print("     â†’ User thÃ­ch biá»ƒn trong train â†’ cÃ³ thá»ƒ predict biá»ƒn trong test")
            print()
        else:
            print("   âš ï¸  THáº¤P: Test items cÃ³ tags khÃ¡c xa train items")
            print("     â†’ KhÃ³ cho model Ä‘á»ƒ generalize")
            print("     â†’ CÃ³ thá»ƒ do user khÃ´ng consistent trong preferences")
            print()
        
        print("=" * 80)
        print("ğŸ¯ Káº¾T LUáº¬N:")
        print("=" * 80)
        print()
        print("âœ“ PHÆ¯Æ NG PHÃP EVALUATION Há»¢P LÃ vÃ¬:")
        print()
        print("1. Sá»­ dá»¥ng Train/Test Split chuáº©n trong Machine Learning")
        print("   â€¢ Giáº¥u má»™t pháº§n interactions Ä‘á»ƒ kiá»ƒm tra kháº£ nÄƒng dá»± Ä‘oÃ¡n")
        print("   â€¢ Ground truth = Items user thá»±c sá»± thÃ­ch (score cao)")
        print()
        print("2. Metrics phÃ¹ há»£p:")
        print("   â€¢ Precision@K: % recommendations Ä‘Ãºng trong top-K")
        print("   â€¢ Recall@K: % relevant items Ä‘Æ°á»£c tÃ¬m tháº¥y")
        print("   â€¢ NDCG@K: ÄÃ¡nh giÃ¡ ranking quality")
        print()
        print("3. Giáº£ Ä‘á»‹nh há»£p lÃ½:")
        print("   â€¢ User thÃ­ch items trong quÃ¡ khá»© (score cao)")
        print("   â€¢ â†’ CÃ³ thá»ƒ thÃ­ch items tÆ°Æ¡ng tá»± trong tÆ°Æ¡ng lai")
        print("   â€¢ Model há»c patterns tá»« train Ä‘á»ƒ predict test")
        print()
        
        if avg_overlap > 0.6:
            print("âœ“ Dá»® LIá»†U HIá»†N Táº I: PhÃ¹ há»£p cho evaluation")
            print("  â€¢ Users cÃ³ preferences tÆ°Æ¡ng Ä‘á»‘i consistent")
            print("  â€¢ Model cÃ³ thá»ƒ há»c vÃ  generalize Ä‘Æ°á»£c")
        else:
            print("âš ï¸  Dá»® LIá»†U HIá»†N Táº I: Cáº§n cáº£i thiá»‡n")
            print("  â€¢ Users khÃ´ng consistent trong preferences")
            print("  â€¢ NÃªn táº¡o synthetic data vá»›i preferences rÃµ rÃ ng hÆ¡n")
            print("  â€¢ â†’ Sá»­ dá»¥ng create_improved_test_data.py")
        
        print()
        print("=" * 80)
        print("ğŸ“ TÃ“M Láº I:")
        print("=" * 80)
        print()
        print("â€¢ Ground truth = Test set (items Ä‘Ã£ giáº¥u Ä‘i)")
        print("â€¢ Model KHÃ”NG biáº¿t test items khi training")
        print("â€¢ Precision/Recall Ä‘o Ä‘á»™ chÃ­nh xÃ¡c khi dá»± Ä‘oÃ¡n test items")
        print("â€¢ Náº¿u model recommend Ä‘Ãºng test items â†’ Precision/Recall cao")
        print("â€¢ Náº¿u model recommend sai â†’ Precision/Recall tháº¥p")
        print()
    
    def close(self):
        self.conn.close()


def main():
    # Database á»Ÿ parent directory (backend/)
    db_path = Path(__file__).parent.parent / "vietnamtravel.db"
    
    if not db_path.exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y database: {db_path}")
        return
    
    print(f"ğŸ“‚ Database: {db_path}")
    print()
    
    analyzer = EvaluationMethodologyAnalyzer(str(db_path))
    
    try:
        analyzer.analyze_evaluation_process()
    finally:
        analyzer.close()


if __name__ == "__main__":
    main()
